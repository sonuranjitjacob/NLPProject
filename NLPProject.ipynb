{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\sonur\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\sonur\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\sonur\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\sonur\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\sonur\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\sonur\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "#Use different approaches here\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "import re\n",
    "\n",
    "#Use different approaches here\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \n",
      "C:\\Users\\sonur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\sonur\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "traindata = pd.read_csv(\"C:\\\\Users\\\\sonur\\\\Downloads\\\\DataScienceProject\\\\DBLPTrainset.txt\", delimiter = '\\t')\n",
    "testdata = pd.read_csv(\"C:\\\\Users\\\\sonur\\\\Downloads\\\\DataScienceProject\\\\DBLPTestset.txt\", delimiter = '\\t')\n",
    "groundtruthdata = pd.read_csv(\"C:\\\\Users\\\\sonur\\\\Downloads\\\\DataScienceProject\\\\DBLPTestGroundTruth.txt\", delimiter = '\\t')\n",
    "\n",
    "path = \"C:\\\\Users\\\\sonur\\\\Downloads\\\\DataScienceProject\\\\DBLPTrainset.txt\" \n",
    "traindata = pd.read_table(path, header=None, names=['num', 'conference', 'papername'])\n",
    "\n",
    "path = \"C:\\\\Users\\\\sonur\\\\Downloads\\\\DataScienceProject\\\\DBLPTestset.txt\" \n",
    "testdata = pd.read_table(path, header=None, names=['num','papername'])\n",
    "\n",
    "\n",
    "path = \"C:\\\\Users\\\\sonur\\\\Downloads\\\\DataScienceProject\\\\DBLPTestGroundTruth.txt\" \n",
    "groundtruthdata = pd.read_table(path, header=None, names=['num','conference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>conference</th>\n",
       "      <th>papername</th>\n",
       "      <th>label_conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>Scalable Serial-parallel Multiplier over GF(2m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SIGGRAPH</td>\n",
       "      <td>Plenoptic sampling.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>Sensitivity and uniformity of a 0.18micrometer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>WWW</td>\n",
       "      <td>A survey of web archive search architectures.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>Understanding dynamic behavior of mm-wave CML ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>SIGGRAPH</td>\n",
       "      <td>Cosine lobe based relighting from gradient ill...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>INFOCOM</td>\n",
       "      <td>Dimensioning an OBS Switch with Partial Wavele...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>A study of identifibility for blind source sep...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>A signal perturbation free semi-blind MRT MIMO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>A low-power V-band CMOS low-noise amplifier us...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>Supply noise insensitive ring VCO with on-chip...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>A 3.3 &amp;micro;W dual-modulus frequency divider ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>A bio-inspired ultrasensitive imaging chip - P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>Digit-serial/parallel multipliers with improve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>WWW</td>\n",
       "      <td>Towards liquid service oriented architectures.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>SIGGRAPH</td>\n",
       "      <td>Adaptive importance sampling for multi-ray gat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>Live demonstration: MWC for real-time applicat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>INFOCOM</td>\n",
       "      <td>Routing and Wavelength Assignment in WDM Rings...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>Current mode multiple-valued adder for cryptog...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>A Model for Integrated Information Systems.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>SIGGRAPH</td>\n",
       "      <td>Webbed Spaces: Between Exhibition and Network ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>WWW</td>\n",
       "      <td>Comparative evaluation of javascript frameworks.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>SIGGRAPH</td>\n",
       "      <td>Infinite 4D fish.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>StreamTX: extracting tuples from streaming XML...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>ASIP Decoder Architecture for Convolutional an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>Privacy-Preserving Indexing of Documents on th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>An Extendible Hash for Multi-Precision Similar...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>A motion compensation system with a high effic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>WWW</td>\n",
       "      <td>Kairos: A Web-Based System for Automatic Gener...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>An On-Chip Delta-Time-to-Voltage Converter for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21613</th>\n",
       "      <td>21613</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>3D Oncological PET volume analysis using CNN a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21614</th>\n",
       "      <td>21614</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>A Vision-based People Counting Approach based ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21615</th>\n",
       "      <td>21615</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>Closed Form Parameters Estimation for Near Fie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21616</th>\n",
       "      <td>21616</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>Unrolling Cycles to Decide Trigger Termination.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21617</th>\n",
       "      <td>21617</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>A new type of microinverter for Photovoltaic p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21618</th>\n",
       "      <td>21618</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>Distributed Online Aggregation.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21619</th>\n",
       "      <td>21619</td>\n",
       "      <td>WWW</td>\n",
       "      <td>ViBE: virtual biology experiments.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21620</th>\n",
       "      <td>21620</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>Accommodating Exceptions in Databases, and Ref...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21621</th>\n",
       "      <td>21621</td>\n",
       "      <td>WWW</td>\n",
       "      <td>Applications of open search tools.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21622</th>\n",
       "      <td>21622</td>\n",
       "      <td>INFOCOM</td>\n",
       "      <td>A Comparison of Media Synchronization Quality ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21623</th>\n",
       "      <td>21623</td>\n",
       "      <td>WWW</td>\n",
       "      <td>Using landing pages for sponsored search ad se...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21624</th>\n",
       "      <td>21624</td>\n",
       "      <td>INFOCOM</td>\n",
       "      <td>Improving AS relationship inference using PoPs.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21625</th>\n",
       "      <td>21625</td>\n",
       "      <td>INFOCOM</td>\n",
       "      <td>Simple Directional Antennas: Improving Perform...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21626</th>\n",
       "      <td>21626</td>\n",
       "      <td>INFOCOM</td>\n",
       "      <td>TCP Sending Rate Control at Terabits Per Second.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21627</th>\n",
       "      <td>21627</td>\n",
       "      <td>INFOCOM</td>\n",
       "      <td>Experimental evaluation of content distributio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21628</th>\n",
       "      <td>21628</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>Low Peak Power ATPG for n-Detection Test.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21629</th>\n",
       "      <td>21629</td>\n",
       "      <td>SIGGRAPH</td>\n",
       "      <td>Applying color theory to creating scientific v...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21630</th>\n",
       "      <td>21630</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>Keyword-aware Optimal Route Search.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21631</th>\n",
       "      <td>21631</td>\n",
       "      <td>SIGGRAPH</td>\n",
       "      <td>Universal capture: image-based facial animatio...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21632</th>\n",
       "      <td>21632</td>\n",
       "      <td>SIGGRAPH</td>\n",
       "      <td>Integrating multiple depth sensors into the vi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21633</th>\n",
       "      <td>21633</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>Correlated jitter sampling for jitter cancella...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21634</th>\n",
       "      <td>21634</td>\n",
       "      <td>WWW</td>\n",
       "      <td>Visualization of Geo-annotated pictures in mob...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21635</th>\n",
       "      <td>21635</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>A new method for matrix description of genetic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21636</th>\n",
       "      <td>21636</td>\n",
       "      <td>WWW</td>\n",
       "      <td>eBag: a ubiquitous Web infrastructure for noma...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21637</th>\n",
       "      <td>21637</td>\n",
       "      <td>INFOCOM</td>\n",
       "      <td>The Peak-Hopper: A New End-to-End Retransmissi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21638</th>\n",
       "      <td>21638</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>Decoding a Family of Dense Codes using the Sum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21639</th>\n",
       "      <td>21639</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>CoHadoop: Flexible Data Placement and Its Expl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21640</th>\n",
       "      <td>21640</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>Full system simulation with QEMU: An approach ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21641</th>\n",
       "      <td>21641</td>\n",
       "      <td>INFOCOM</td>\n",
       "      <td>Localization in non-localizable sensor and ad-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21642</th>\n",
       "      <td>21642</td>\n",
       "      <td>INFOCOM</td>\n",
       "      <td>Topology Control of Multihop Wireless Networks...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21643 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         num conference                                          papername  \\\n",
       "0          0      ISCAS  Scalable Serial-parallel Multiplier over GF(2m...   \n",
       "1          1   SIGGRAPH                                Plenoptic sampling.   \n",
       "2          2      ISCAS  Sensitivity and uniformity of a 0.18micrometer...   \n",
       "3          3        WWW      A survey of web archive search architectures.   \n",
       "4          4      ISCAS  Understanding dynamic behavior of mm-wave CML ...   \n",
       "5          5   SIGGRAPH  Cosine lobe based relighting from gradient ill...   \n",
       "6          6    INFOCOM  Dimensioning an OBS Switch with Partial Wavele...   \n",
       "7          7      ISCAS  A study of identifibility for blind source sep...   \n",
       "8          8      ISCAS  A signal perturbation free semi-blind MRT MIMO...   \n",
       "9          9      ISCAS  A low-power V-band CMOS low-noise amplifier us...   \n",
       "10        10      ISCAS  Supply noise insensitive ring VCO with on-chip...   \n",
       "11        11      ISCAS  A 3.3 &micro;W dual-modulus frequency divider ...   \n",
       "12        12      ISCAS  A bio-inspired ultrasensitive imaging chip - P...   \n",
       "13        13      ISCAS  Digit-serial/parallel multipliers with improve...   \n",
       "14        14        WWW     Towards liquid service oriented architectures.   \n",
       "15        15   SIGGRAPH  Adaptive importance sampling for multi-ray gat...   \n",
       "16        16      ISCAS  Live demonstration: MWC for real-time applicat...   \n",
       "17        17    INFOCOM  Routing and Wavelength Assignment in WDM Rings...   \n",
       "18        18      ISCAS  Current mode multiple-valued adder for cryptog...   \n",
       "19        19       VLDB        A Model for Integrated Information Systems.   \n",
       "20        20   SIGGRAPH  Webbed Spaces: Between Exhibition and Network ...   \n",
       "21        21        WWW   Comparative evaluation of javascript frameworks.   \n",
       "22        22   SIGGRAPH                                  Infinite 4D fish.   \n",
       "23        23       VLDB  StreamTX: extracting tuples from streaming XML...   \n",
       "24        24      ISCAS  ASIP Decoder Architecture for Convolutional an...   \n",
       "25        25       VLDB  Privacy-Preserving Indexing of Documents on th...   \n",
       "26        26       VLDB  An Extendible Hash for Multi-Precision Similar...   \n",
       "27        27      ISCAS  A motion compensation system with a high effic...   \n",
       "28        28        WWW  Kairos: A Web-Based System for Automatic Gener...   \n",
       "29        29      ISCAS  An On-Chip Delta-Time-to-Voltage Converter for...   \n",
       "...      ...        ...                                                ...   \n",
       "21613  21613      ISCAS  3D Oncological PET volume analysis using CNN a...   \n",
       "21614  21614      ISCAS  A Vision-based People Counting Approach based ...   \n",
       "21615  21615      ISCAS  Closed Form Parameters Estimation for Near Fie...   \n",
       "21616  21616       VLDB    Unrolling Cycles to Decide Trigger Termination.   \n",
       "21617  21617      ISCAS  A new type of microinverter for Photovoltaic p...   \n",
       "21618  21618       VLDB                    Distributed Online Aggregation.   \n",
       "21619  21619        WWW                 ViBE: virtual biology experiments.   \n",
       "21620  21620       VLDB  Accommodating Exceptions in Databases, and Ref...   \n",
       "21621  21621        WWW                 Applications of open search tools.   \n",
       "21622  21622    INFOCOM  A Comparison of Media Synchronization Quality ...   \n",
       "21623  21623        WWW  Using landing pages for sponsored search ad se...   \n",
       "21624  21624    INFOCOM    Improving AS relationship inference using PoPs.   \n",
       "21625  21625    INFOCOM  Simple Directional Antennas: Improving Perform...   \n",
       "21626  21626    INFOCOM   TCP Sending Rate Control at Terabits Per Second.   \n",
       "21627  21627    INFOCOM  Experimental evaluation of content distributio...   \n",
       "21628  21628      ISCAS          Low Peak Power ATPG for n-Detection Test.   \n",
       "21629  21629   SIGGRAPH  Applying color theory to creating scientific v...   \n",
       "21630  21630       VLDB                Keyword-aware Optimal Route Search.   \n",
       "21631  21631   SIGGRAPH  Universal capture: image-based facial animatio...   \n",
       "21632  21632   SIGGRAPH  Integrating multiple depth sensors into the vi...   \n",
       "21633  21633      ISCAS  Correlated jitter sampling for jitter cancella...   \n",
       "21634  21634        WWW  Visualization of Geo-annotated pictures in mob...   \n",
       "21635  21635      ISCAS  A new method for matrix description of genetic...   \n",
       "21636  21636        WWW  eBag: a ubiquitous Web infrastructure for noma...   \n",
       "21637  21637    INFOCOM  The Peak-Hopper: A New End-to-End Retransmissi...   \n",
       "21638  21638      ISCAS  Decoding a Family of Dense Codes using the Sum...   \n",
       "21639  21639       VLDB  CoHadoop: Flexible Data Placement and Its Expl...   \n",
       "21640  21640      ISCAS  Full system simulation with QEMU: An approach ...   \n",
       "21641  21641    INFOCOM  Localization in non-localizable sensor and ad-...   \n",
       "21642  21642    INFOCOM  Topology Control of Multihop Wireless Networks...   \n",
       "\n",
       "       label_conference  \n",
       "0                     0  \n",
       "1                     4  \n",
       "2                     0  \n",
       "3                     3  \n",
       "4                     0  \n",
       "5                     4  \n",
       "6                     1  \n",
       "7                     0  \n",
       "8                     0  \n",
       "9                     0  \n",
       "10                    0  \n",
       "11                    0  \n",
       "12                    0  \n",
       "13                    0  \n",
       "14                    3  \n",
       "15                    4  \n",
       "16                    0  \n",
       "17                    1  \n",
       "18                    0  \n",
       "19                    2  \n",
       "20                    4  \n",
       "21                    3  \n",
       "22                    4  \n",
       "23                    2  \n",
       "24                    0  \n",
       "25                    2  \n",
       "26                    2  \n",
       "27                    0  \n",
       "28                    3  \n",
       "29                    0  \n",
       "...                 ...  \n",
       "21613                 0  \n",
       "21614                 0  \n",
       "21615                 0  \n",
       "21616                 2  \n",
       "21617                 0  \n",
       "21618                 2  \n",
       "21619                 3  \n",
       "21620                 2  \n",
       "21621                 3  \n",
       "21622                 1  \n",
       "21623                 3  \n",
       "21624                 1  \n",
       "21625                 1  \n",
       "21626                 1  \n",
       "21627                 1  \n",
       "21628                 0  \n",
       "21629                 4  \n",
       "21630                 2  \n",
       "21631                 4  \n",
       "21632                 4  \n",
       "21633                 0  \n",
       "21634                 3  \n",
       "21635                 0  \n",
       "21636                 3  \n",
       "21637                 1  \n",
       "21638                 0  \n",
       "21639                 2  \n",
       "21640                 0  \n",
       "21641                 1  \n",
       "21642                 1  \n",
       "\n",
       "[21643 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata['label_conference'] = traindata.conference.map({'ISCAS':0, 'INFOCOM':1, 'VLDB':2, 'WWW':3, 'SIGGRAPH':4})\n",
    "traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISCAS       2043\n",
       "INFOCOM      502\n",
       "WWW          423\n",
       "VLDB         219\n",
       "SIGGRAPH     186\n",
       "Name: conference, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruthdata.conference.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>conference</th>\n",
       "      <th>label_conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ISCAS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>WWW</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SIGGRAPH</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num conference  label_conference\n",
       "0    0      ISCAS                 0\n",
       "1    1      ISCAS                 0\n",
       "2    2      ISCAS                 0\n",
       "3    3        WWW                 3\n",
       "4    4   SIGGRAPH                 4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruthdata['label_conference'] = groundtruthdata.conference.map({'ISCAS':0, 'INFOCOM':1, 'VLDB':2, 'WWW':3, 'SIGGRAPH':4})\n",
    "groundtruthdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "(21643,)\n",
      "(21643,)\n"
     ]
    }
   ],
   "source": [
    "X_train = traindata.papername\n",
    "y_train = traindata.label_conference\n",
    "print('finished')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14685\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_train_dtm\n",
    "print(X_train_dtm.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3373,)\n",
      "(3373,)\n"
     ]
    }
   ],
   "source": [
    "X_test = testdata.papername\n",
    "y_test = groundtruthdata.label_conference\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      2043\n",
      "           1       0.74      0.79      0.77       502\n",
      "           2       0.56      0.74      0.64       219\n",
      "           3       0.77      0.77      0.77       423\n",
      "           4       0.78      0.73      0.75       186\n",
      "\n",
      "    accuracy                           0.86      3373\n",
      "   macro avg       0.76      0.79      0.77      3373\n",
      "weighted avg       0.87      0.86      0.86      3373\n",
      "\n",
      "0.8612511117699377\n",
      "0.8612511117699377\n",
      "Results MultinomialNB\n",
      "Confusion matrix using MultinomialNB: \n",
      " [[1883   86   45    9   20]\n",
      " [  28  399   27   42    6]\n",
      " [   5   17  163   32    2]\n",
      " [   5   34   50  325    9]\n",
      " [  30    4    5   12  135]]\n",
      "\n",
      "Accuracy:  0.8612511117699377\n",
      "Precision:  0.8612511117699377\n",
      "Recall:  0.8612511117699377\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#use final approach selected here\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_test_pred = nb.predict(X_test_dtm)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_test_pred))\n",
    "print(metrics.accuracy_score(y_test,y_test_pred))\n",
    "print(f1_score(y_test, y_test_pred, average='micro'))\n",
    "\n",
    "results = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Results MultinomialNB\")\n",
    "print('Confusion matrix using MultinomialNB: \\n', results)\n",
    "\n",
    "\n",
    "print(\"\\nAccuracy: \", accuracy_score(y_test, y_test_pred)) # accuracy for multilabel\n",
    "print(\"Precision: \",precision_score(y_test, y_test_pred, average='micro'))\n",
    "print(\"Recall: \",recall_score(y_test, y_test_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Feature Extraction\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 'The quick brown'\n",
    "def Preprocessing(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    traindata_stop = []\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    wordsFiltered =[]\n",
    "    wordsFiltered_complete = []\n",
    "\n",
    "    from nltk.stem import PorterStemmer\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "\n",
    "    for title in text:\n",
    "        s = re.sub(r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]+\\ *\", \" \", title) #remove punctuation\n",
    "        #no_number = re.sub(r'\\d+', '', s).lower()#remove numbers\n",
    "        words = word_tokenize(s.lower())\n",
    "        #result=[w for w in words if len(w) > 1] #remove single characters\n",
    "        x = []\n",
    "        for w in words:        \n",
    "            a =lemmatizer.lemmatize(w)  #lemmatizer.lemmatize(w) #ps.stem(w) \n",
    "            if a not in stopWords:\n",
    "                x.append(a)\n",
    "            wordsFiltered = TreebankWordDetokenizer().detokenize(x)\n",
    "        wordsFiltered_complete.append(wordsFiltered)\n",
    "\n",
    "    text_processed = pd.DataFrame(wordsFiltered_complete, columns=['papername'])\n",
    "\n",
    "    return text_processed.papername\n",
    "    #print(X_train)\n",
    "\n",
    "X_train=Preprocessing(X_train)\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "\n",
    "X_test=Preprocessing(X_test)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13182"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      2043\n",
      "           1       0.78      0.81      0.79       502\n",
      "           2       0.62      0.72      0.67       219\n",
      "           3       0.85      0.70      0.77       423\n",
      "           4       0.93      0.59      0.72       186\n",
      "\n",
      "    accuracy                           0.87      3373\n",
      "   macro avg       0.82      0.76      0.78      3373\n",
      "weighted avg       0.88      0.87      0.87      3373\n",
      "\n",
      "0.8737029350726356\n",
      "0.8737029350726356\n",
      "Results MultinomialNB\n",
      "Confusion matrix using MultinomialNB: \n",
      " [[1979   41   20    1    2]\n",
      " [  53  406   19   21    3]\n",
      " [  18   19  158   23    1]\n",
      " [  28   46   52  295    2]\n",
      " [  55    8    6    8  109]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "With only Naive Bayes, the accuracy is 82 percent / 81 with some pre-processing\n",
    "\"\"\"\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def NaiveBayes(X_train_dtm,y_train,X_test_dtm,y_test):\n",
    "    text_clf = Pipeline([#('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "#                         ('pca', PCA()),\n",
    "                         ('clf', MultinomialNB()),\n",
    "                         ])\n",
    "    text_clf.fit(X_train_dtm, y_train)\n",
    "    predicted = text_clf.predict(X_test_dtm)\n",
    "    return predicted\n",
    "\n",
    "predicted=NaiveBayes(X_train_dtm,y_train,X_test_dtm,y_test)\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "print(metrics.accuracy_score(predicted,y_test))\n",
    "print(f1_score(y_test, predicted, average='micro'))\n",
    "\n",
    "\n",
    "results = confusion_matrix(y_test, predicted)\n",
    "print(\"Results MultinomialNB\")\n",
    "print('Confusion matrix using MultinomialNB: \\n', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      2043\n",
      "           1       0.75      0.78      0.76       502\n",
      "           2       0.51      0.75      0.60       219\n",
      "           3       0.74      0.73      0.74       423\n",
      "           4       0.59      0.78      0.67       186\n",
      "\n",
      "    accuracy                           0.83      3373\n",
      "   macro avg       0.71      0.79      0.74      3373\n",
      "weighted avg       0.85      0.83      0.84      3373\n",
      "\n",
      "0.832196857396976\n",
      "0.832196857396976\n",
      "Results MultinomialNB\n",
      "Confusion matrix using MultinomialNB: \n",
      " [[1795   96   57   31   64]\n",
      " [  31  392   32   33   14]\n",
      " [   6    9  164   33    7]\n",
      " [  12   25   59  310   17]\n",
      " [  16    2   12   10  146]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SVC gives an accuracy of 83.6, without tfidf, it gives 81.3 \n",
    "->SVC gives an accuracy of 84.53 not preprocessed without tfidf, 82.9, preprocessed without tfidf, \n",
    "it gives 84.42 not preprocessed with tfid and  84.96 with tfidf preprocessed\n",
    "\n",
    "Comment out the tf idf line in the pipeline to check this\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# X_train = X_train_new\n",
    "# X_test = X_test_new\n",
    "# y_train = y_train\n",
    "# y_test = y_test\n",
    "def SVC(X_train_dtm,y_train,X_test_dtm,y_test):\n",
    "    text_clf = Pipeline([#('vect', CountVectorizer()),\n",
    "#                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', LinearSVC()),\n",
    "                         ])\n",
    "    text_clf.fit(X_train_dtm, y_train)\n",
    "    predicted = text_clf.predict(X_test_dtm)\n",
    "    return predicted\n",
    "\n",
    "predicted=SVC(X_train_dtm,y_train,X_test_dtm,y_test)\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "print(metrics.accuracy_score(y_test, predicted))\n",
    "print(f1_score(y_test, predicted, average='micro'))\n",
    "\n",
    "results = confusion_matrix(y_test, predicted)\n",
    "print(\"Results MultinomialNB\")\n",
    "print('Confusion matrix using MultinomialNB: \\n', results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def Sparse_matrix(y): #create sparse matrix for labels\n",
    "    type_labels = list(set(y))\n",
    "    label_vector=[]\n",
    "    for i in y: \n",
    "        label_line=[]\n",
    "        for l in type_labels:\n",
    "            if l == i:\n",
    "                label_line.append(1)\n",
    "            else:\n",
    "                label_line.append(0)\n",
    "        label_vector.append(label_line)\n",
    "    y_sparse=np.array(label_vector)\n",
    "    return y_sparse\n",
    "\n",
    "def DNN(X_train_dtm,y_train,X_test_dtm,y_test):\n",
    "\n",
    "    input_dim = X_train_dtm.shape[1]\n",
    "    y_train_sparse=Sparse_matrix(y_train)\n",
    "    y_test_sparse=Sparse_matrix(y_test)\n",
    "\n",
    "\n",
    "    NN_classifier = Sequential()\n",
    "    #First Hidden Layer\n",
    "    NN_classifier.add(Dense(10, activation='relu', kernel_initializer='random_normal', input_dim=input_dim)) #input number of vocabulary\n",
    "    #Second  Hidden Layer\n",
    "    NN_classifier.add(Dense(10, activation='relu', kernel_initializer='random_normal'))\n",
    "    #Output Layer\n",
    "    NN_classifier.add(Dense(5, activation='sigmoid', kernel_initializer='random_normal')) #output 5 classes\n",
    "    #Compiling the neural network\n",
    "    NN_classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "    #Fitting the data to the training dataset\n",
    "    NN_classifier.fit(X_train_dtm,y_train_sparse, batch_size=10, epochs=20)\n",
    "    eval_model=NN_classifier.evaluate(X_train_dtm, y_train_sparse)\n",
    "    eval_model\n",
    "    \n",
    "    y_tst_pred=NN_classifier.predict(X_test_dtm)\n",
    "    y_tst_pred =(y_tst_pred>=0.5)\n",
    "    return (y_test_sparse, y_tst_pred)\n",
    "\n",
    "#print(y_tst_pred)\n",
    "# y_test_sparse, y_tst_pred=DNN(X_train_dtm,y_train,X_test_dtm,y_test)\n",
    "# print(metrics.classification_report(y_test_sparse, y_tst_pred))\n",
    "# metrics.accuracy_score(y_tst_pred, y_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "\n",
      "TRAIN: [ 4329  4330  4331 ... 21640 21641 21642] TEST: [   0    1    2 ... 4326 4327 4328]\n",
      "WARNING:tensorflow:From C:\\Users\\sonur\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\sonur\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "17314/17314 [==============================] - 4s 254us/step - loss: 0.4362 - accuracy: 0.83010s - l\n",
      "Epoch 2/20\n",
      "17314/17314 [==============================] - 5s 285us/step - loss: 0.2935 - accuracy: 0.8699\n",
      "Epoch 3/20\n",
      "17314/17314 [==============================] - 4s 237us/step - loss: 0.1873 - accuracy: 0.9114\n",
      "Epoch 4/20\n",
      "17314/17314 [==============================] - 4s 236us/step - loss: 0.1499 - accuracy: 0.9235\n",
      "Epoch 5/20\n",
      "17314/17314 [==============================] - 4s 238us/step - loss: 0.1300 - accuracy: 0.9398\n",
      "Epoch 6/20\n",
      "17314/17314 [==============================] - 4s 237us/step - loss: 0.1062 - accuracy: 0.9650\n",
      "Epoch 7/20\n",
      "17314/17314 [==============================] - 4s 257us/step - loss: 0.0779 - accuracy: 0.9767\n",
      "Epoch 8/20\n",
      "17314/17314 [==============================] - 4s 259us/step - loss: 0.0588 - accuracy: 0.9823\n",
      "Epoch 9/20\n",
      "17314/17314 [==============================] - 5s 271us/step - loss: 0.0461 - accuracy: 0.9864\n",
      "Epoch 10/20\n",
      "17314/17314 [==============================] - 5s 270us/step - loss: 0.0372 - accuracy: 0.9888\n",
      "Epoch 11/20\n",
      "17314/17314 [==============================] - 4s 255us/step - loss: 0.0303 - accuracy: 0.9913\n",
      "Epoch 12/20\n",
      "17314/17314 [==============================] - 4s 248us/step - loss: 0.0249 - accuracy: 0.9927\n",
      "Epoch 13/20\n",
      "17314/17314 [==============================] - 5s 260us/step - loss: 0.0210 - accuracy: 0.9940\n",
      "Epoch 14/20\n",
      "17314/17314 [==============================] - 4s 257us/step - loss: 0.0174 - accuracy: 0.9950\n",
      "Epoch 15/20\n",
      "17314/17314 [==============================] - 5s 281us/step - loss: 0.0147 - accuracy: 0.9959\n",
      "Epoch 16/20\n",
      "17314/17314 [==============================] - 4s 257us/step - loss: 0.0124 - accuracy: 0.9968\n",
      "Epoch 17/20\n",
      "17314/17314 [==============================] - 5s 266us/step - loss: 0.0106 - accuracy: 0.9972\n",
      "Epoch 18/20\n",
      "17314/17314 [==============================] - 5s 271us/step - loss: 0.0090 - accuracy: 0.9976\n",
      "Epoch 19/20\n",
      "17314/17314 [==============================] - 5s 268us/step - loss: 0.0079 - accuracy: 0.9980\n",
      "Epoch 20/20\n",
      "17314/17314 [==============================] - 4s 254us/step - loss: 0.0068 - accuracy: 0.9983\n",
      "17314/17314 [==============================] - 2s 106us/step\n",
      "DNN \tPrecision:  0.811965811965812 \trecall 0.8193473193473193 \tf1 0.815639865413621\n",
      "\n",
      "TRAIN: [    0     1     2 ... 21640 21641 21642] TEST: [4329 4330 4331 ... 8655 8656 8657]\n",
      "Epoch 1/20\n",
      "17314/17314 [==============================] - 5s 276us/step - loss: 0.4261 - accuracy: 0.8358\n",
      "Epoch 2/20\n",
      "17314/17314 [==============================] - 4s 258us/step - loss: 0.2813 - accuracy: 0.8768\n",
      "Epoch 3/20\n",
      " 3240/17314 [====>.........................] - ETA: 4s - loss: 0.1855 - accuracy: 0.9167"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold # import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "kf = KFold(n_splits=5) # Define the split - into 2 folds \n",
    "kf.get_n_splits(traindata) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf) \n",
    "NB_avg=0\n",
    "SVC_avg=0\n",
    "DNN_avg=0\n",
    "\n",
    "for train_index, test_index in kf.split(traindata.papername):\n",
    "    print('\\nTRAIN:', train_index, 'TEST:', test_index)\n",
    "    X_train0, X_test0 = traindata.papername[train_index], traindata.papername[test_index]\n",
    "    y_train, y_test = traindata.label_conference[train_index], traindata.label_conference[test_index]   \n",
    "    \n",
    "    X_train=Preprocessing(X_train0)\n",
    "    vect = TfidfVectorizer()\n",
    "    vect.fit(X_train)\n",
    "    X_train_dtm = vect.transform(X_train)\n",
    "\n",
    "    X_test=Preprocessing(X_test0)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    \n",
    "#     X_train_dtm,X_test_dtm=autoencoder(X_train_dtm,X_test_dtm)\n",
    "    \n",
    "#     predicted=NaiveBayes(X_train_dtm,y_train,X_test_dtm,y_test)\n",
    "#     #print(metrics.classification_report(y_test, predicted))\n",
    "#     precision=precision_score(predicted, y_test, average='micro')\n",
    "#     recall=recall_score(predicted, y_test, average='micro')\n",
    "#     f1=f1_score(predicted, y_test, average='micro')\n",
    "#     print(\"Naive Bayes\",\"\\tPrecision: \",precision, \"\\trecall\", recall, \"\\tf1\", f1)\n",
    "#     NB_avg=NB_avg+precision\n",
    "        \n",
    "#     predicted=SVC(X_train_dtm,y_train,X_test_dtm,y_test)\n",
    "#     #print(metrics.classification_report(y_test, predicted))\n",
    "#     precision=precision_score(predicted, y_test, average='micro')\n",
    "#     recall=recall_score(predicted, y_test, average='micro')\n",
    "#     f1=f1_score(predicted, y_test, average='micro')\n",
    "#     print(\"SVC\",\"\\tPrecision: \",precision, \"\\trecall\", recall, \"\\tf1\", f1)\n",
    "#     SVC_avg=SVC_avg+precision\n",
    "    \n",
    "    y_test_sparse, y_tst_pred=DNN(X_train_dtm,y_train,X_test_dtm,y_test)\n",
    "    #print(metrics.classification_report(y_test, predicted))\n",
    "    precision=precision_score(y_tst_pred, y_test_sparse, average='micro')\n",
    "    recall=recall_score(y_tst_pred, y_test_sparse, average='micro')\n",
    "    f1=f1_score(y_tst_pred, y_test_sparse, average='micro')\n",
    "    print(\"DNN\",\"\\tPrecision: \",precision, \"\\trecall\", recall, \"\\tf1\", f1)\n",
    "    DNN_avg=DNN_avg+precision\n",
    "\n",
    "# print(\"NB_avg\",NB_avg/5)    \n",
    "# print(\"SVC_avg\",SVC_avg/5)    \n",
    "print(\"DNN_avg\",DNN_avg/5)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
